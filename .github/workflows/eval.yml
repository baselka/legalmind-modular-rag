name: RAG Quality Evaluation

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          enable-cache: true
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: uv pip install --system -r requirements.txt
      - name: Run unit tests
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: uv run pytest tests/unit/ -v --tb=short

  rag-evaluation:
    name: RAG Quality Gates
    runs-on: ubuntu-latest
    needs: unit-tests
    services:
      qdrant:
        image: qdrant/qdrant:latest
        ports:
          - 6333:6333
      redis:
        image: redis:latest
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          enable-cache: true
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: uv pip install --system -r requirements.txt

      - name: Start RAG Backend
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          QDRANT_URL: http://localhost:6333
          REDIS_URL: redis://localhost:6379
        run: |
          uv run uvicorn main:app --host 0.0.0.0 --port 8000 &
          # Wait for server to be ready
          for i in {1..30}; do
            if curl -s http://localhost:8000/api/v1/health | grep -q 'healthy'; then
              echo "Server is ready!"
              break
            fi
            echo "Waiting for server... ($i/30)"
            sleep 5
          done

      - name: Ingest Sample Documents
        run: |
          # The RAG benchmark needs data to retrieve!
          # Ingesting the core legal documents used in the golden dataset.
          curl -X POST http://localhost:8000/api/v1/ingest -F "file=@sample_docs/contract_acme_services_2023.pdf"
          curl -X POST http://localhost:8000/api/v1/ingest -F "file=@sample_docs/case_file_henderson_v_blackwood_2022.pdf"
          curl -X POST http://localhost:8000/api/v1/ingest -F "file=@sample_docs/nda_globex_stellartech_2023.pdf"
          curl -X POST http://localhost:8000/api/v1/ingest -F "file=@sample_docs/brief_motion_summary_judgment_2022.pdf"
          curl -X POST http://localhost:8000/api/v1/ingest -F "file=@sample_docs/employment_agreement_cto_2023.pdf"

      - name: Run RAG Quality Gates (System Benchmark)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          API_URL: http://localhost:8000/api/v1/query
          EVAL_FAITHFULNESS_THRESHOLD: "0.9" # Requirement: Fail build if < 0.9
          EVAL_RELEVANCE_THRESHOLD: "0.8"
          EVAL_CONTEXT_PRECISION_THRESHOLD: "0.8"
        run: |
          # Use deepeval to run the benchmark test against the live backend
          uv run deepeval test run tests/eval/test_rag_benchmark.py -v

      - name: Upload eval results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: eval-results
          path: .deepeval/
          retention-days: 30
